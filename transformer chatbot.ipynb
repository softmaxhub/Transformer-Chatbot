{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13597,"status":"ok","timestamp":1655405800998,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"_0epyvoW22tA"},"outputs":[],"source":["# inspired by fawazsammani\n","\n","\n","import math\n","from collections import Counter\n","import json\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1655405801001,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"DVxhSxnr3Zl5"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617,"status":"ok","timestamp":1655405802002,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"gghRebQL6Iso","outputId":"2371c02f-ebd1-4b68-b30b-9ec0f752fb57"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-06-16 18:56:46--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n","Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n","Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9916637 (9.5M) [application/zip]\n","Saving to: ‘cornell_movie_dialogs_corpus.zip’\n","\n","cornell_movie_dialo 100%[===================>]   9.46M  58.4MB/s    in 0.2s    \n","\n","2022-06-16 18:56:46 (58.4 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n","\n","Archive:  cornell_movie_dialogs_corpus.zip\n","   creating: cornell movie-dialogs corpus/\n","  inflating: cornell movie-dialogs corpus/.DS_Store  \n","   creating: __MACOSX/\n","   creating: __MACOSX/cornell movie-dialogs corpus/\n","  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n","  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n","  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n","  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n","  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n","  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n","  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n","  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n","  inflating: cornell movie-dialogs corpus/README.txt  \n","  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n","'cornell movie-dialogs corpus'\t    __MACOSX\n"," cornell_movie_dialogs_corpus.zip   sample_data\n"]}],"source":["!wget -nc http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n","!unzip -n cornell_movie_dialogs_corpus.zip\n","!ls"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1655405802003,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"w7lZ_Wnj22tj"},"outputs":[],"source":["corpus_movie_conv = 'cornell movie-dialogs corpus/movie_conversations.txt'\n","corpus_movie_lines = 'cornell movie-dialogs corpus/movie_lines.txt'\n","max_len = 25"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":45,"status":"ok","timestamp":1655405802007,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"U3_ICbnp22tq"},"outputs":[],"source":["with open(corpus_movie_conv, 'r') as c:\n","    conv = c.readlines()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1655405802008,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"rr18LoDa22tv"},"outputs":[],"source":["with open(corpus_movie_lines, 'r', encoding='iso-8859-1') as l:\n","    lines = l.readlines()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1655405802009,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"Fw2FB-Wa22ty"},"outputs":[],"source":["lines_dic = {}\n","for line in lines:\n","    objects = line.split(\" +++$+++ \")\n","    lines_dic[objects[0]] = objects[-1]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1655405802011,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"K11VMCB-22t1"},"outputs":[],"source":["def remove_punc(string):\n","    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n","    no_punct = \"\"\n","    for char in string:\n","        if char not in punctuations:\n","            no_punct = no_punct + char  # space is also a character\n","    return no_punct.lower()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6566,"status":"ok","timestamp":1655405808538,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"KiVgmQuH22t8"},"outputs":[],"source":["pairs = []\n","for con in conv:\n","    ids = eval(con.split(\" +++$+++ \")[-1])\n","    for i in range(len(ids)):\n","        qa_pairs = []\n","        \n","        if i==len(ids)-1:\n","            break\n","        \n","        first = remove_punc(lines_dic[ids[i]].strip())      \n","        second = remove_punc(lines_dic[ids[i+1]].strip())\n","        qa_pairs.append(first.split()[:max_len])\n","        qa_pairs.append(second.split()[:max_len])\n","        pairs.append(qa_pairs)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":55,"status":"ok","timestamp":1655405808541,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"JyFWxCXK22uD"},"outputs":[],"source":["word_freq = Counter()\n","for pair in pairs:\n","    word_freq.update(pair[0])\n","    word_freq.update(pair[1])"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":53,"status":"ok","timestamp":1655405808543,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"vf50HOxq22uI"},"outputs":[],"source":["min_word_freq = 5\n","words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n","word_map = {k: v + 1 for v, k in enumerate(words)}\n","word_map['<start>'] = len(word_map) + 1      # len(word_map) increases after each step\n","word_map['<end>'] = len(word_map) + 1\n","word_map['<unk>'] = len(word_map) + 1\n","word_map['<pad>'] = 0"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54,"status":"ok","timestamp":1655405808545,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"jx3L6TVY22uP","outputId":"b89bc87f-f592-430e-dfef-c659aef9c20e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total words are: 18243\n"]}],"source":["print(f\"Total words are: {len(word_map)}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":50,"status":"ok","timestamp":1655405808547,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"clH9mWIj22uU"},"outputs":[],"source":["with open('WORDMAP_corpus.json', 'w') as j:\n","    json.dump(word_map, j)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":52,"status":"ok","timestamp":1655405808551,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"vNcNc5Yy22uW"},"outputs":[],"source":["def encode_question(words, word_map):\n","    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n","    return enc_c"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":53,"status":"ok","timestamp":1655405808554,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"iBhBLnyg22uY"},"outputs":[],"source":["def encode_reply(words, word_map):\n","    \n","    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + \\\n","            [word_map['<end>']] + [word_map['<pad>']] * (max_len - len(words))\n","\n","\n","    return enc_c"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2869,"status":"ok","timestamp":1655405811372,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"G_UyPk6422ua"},"outputs":[],"source":["pairs_encoded = []\n","for pair in pairs:\n","    qus = encode_question(pair[0], word_map)\n","    ans = encode_reply(pair[1], word_map)\n","    pairs_encoded.append([qus, ans])"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7928,"status":"ok","timestamp":1655405819285,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"9K7OTKLg22x0"},"outputs":[],"source":["with open('pairs_encoded.json', 'w') as p:\n","    json.dump(pairs_encoded, p)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1655405819287,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"z-tR_17w22x1"},"outputs":[],"source":["# rev_word_map = {v: k for k, v in word_map.items()}\n","# ' '.join([rev_word_map[v] for v in pairs_encoded[1][0]])"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1655405819291,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"-WEHqoOR22x3"},"outputs":[],"source":["class Dataset(Dataset):\n","\n","    def __init__(self):\n","\n","        self.pairs = json.load(open('pairs_encoded.json'))\n","        self.dataset_size = len(self.pairs)\n","\n","    def __getitem__(self, i):\n","        \n","        question = torch.LongTensor(self.pairs[i][0])\n","        reply = torch.LongTensor(self.pairs[i][1])\n","            \n","        return question, reply\n","\n","    def __len__(self):\n","        return self.dataset_size"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":2433,"status":"ok","timestamp":1655405821679,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"cYkpFJY022x7"},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(Dataset(),\n","\n","                                          #  batch_size=100,\n","                                           batch_size=64,\n","\n","                                           shuffle=True, \n","                                           pin_memory=True)\n","\n","                                           "]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":96,"status":"ok","timestamp":1655405821685,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"lpEqcaMU22x_"},"outputs":[],"source":["# question, reply = next(iter(train_loader))"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":102,"status":"ok","timestamp":1655405821694,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"DTfyuIjE22yL"},"outputs":[],"source":["def create_masks(question, reply_input, reply_target):\n","    \n","    def subsequent_mask(size):\n","        mask = torch.tril(torch.ones(size, size)).type(dtype=torch.uint8)\n","        return mask.unsqueeze(0)\n","    \n","    \n","    # question    : <start>  I     went   home <end>\n","    # reply_input : <start>  I     went   home\n","    # reply_target:   I     went   home   <end>\n","    \n","    question_mask = question != 0\n","    question_mask = question_mask.to(device)\n","    question_mask = question_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n","     \n","    reply_input_mask = reply_input != 0\n","    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n","    \n","    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data)\n","    # (batch_size, 1, max_words) & (1, max_words, max_words) --> (batch_size, max_words, max_words)\n","    \n","    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n","    \n","    reply_target_mask = reply_target != 0              # (batch_size, max_words)\n","    \n","\n","\n","    return question_mask, reply_input_mask, reply_target_mask\n","    "]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":105,"status":"ok","timestamp":1655405821698,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"wxAmomOo22y3"},"outputs":[],"source":["# class Embeddings(nn.Module):\n","#     \"\"\"\n","#     Implements embeddings of the words and adds their positional encodings. \n","#     \"\"\"\n","#     def __init__(self, vocab_size, d_model, max_len=50):\n","#         super(Embeddings, self).__init__()\n","#         self.d_model = d_model\n","#         self.dropout = nn.Dropout(0.1)\n","#         self.embed = nn.Embedding(vocab_size, d_model)\n","#         self.pe = self.create_positinal_encoding(max_len, self.d_model) # (1, max_len, d_model)\n","#         self.dropout = nn.Dropout(0.1)\n","        \n","\n","#     def create_positinal_encoding(self, max_len, d_model):\n","#         pe = torch.zeros(max_len, d_model).to(device)\n","#         for pos in range(max_len):   # for each position of the word\n","#             for i in range(0, d_model, 2):   # for each dimension of the each position\n","#                 pe[pos, i]   = math.sin(pos / ( 10000 ** ( (2 * i) / d_model ) ))\n","#                 pe[pos, i+1] = math.cos(pos / ( 10000 ** ( (2 * (i + 1)) / d_model ) ))\n","#         pe = pe.unsqueeze(0)   # include the batch size, (1, max_len, d_model)\n","        \n","#         return pe\n","        \n","\n","\n","#     def forward(self, encoded_words):\n","\n","#       embedding = self.embed(encoded_words) * math.sqrt(self.d_model)    # (batch_size, max_words, d_model)      \n","\n","#       # max_words = embedding.size(1)\n","#       embedding += self.pe[:, :embedding.size(1)]    # 'pe' will automatically be expanded with\n","#                                                      # the same batch_size as encoded_words\n","      \n","#       embedding = self.dropout(embedding)        \n","      \n","\n","#       return embedding\n","      "]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":104,"status":"ok","timestamp":1655405821700,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"TRM_Q0Y23Zng"},"outputs":[],"source":["class Embeddings(nn.Module):\n","    \"\"\"\n","    Implements embeddings of the words and adds their positional encodings. \n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, max_len=50, num_layers=6):\n","        super(Embeddings, self).__init__()\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(0.1)\n","        self.embed = nn.Embedding(vocab_size, d_model)\n","        self.pe = self.create_positinal_encoding(max_len, self.d_model)     # (1, max_len, d_model)\n","        self.te = self.create_positinal_encoding(num_layers, self.d_model)  # (1, num_layers, d_model)\n","        self.dropout = nn.Dropout(0.1)\n","        \n","        \n","    def create_positinal_encoding(self, max_len, d_model):\n","        pe = torch.zeros(max_len, d_model).to(device)\n","        for pos in range(max_len):   # for each position of the word\n","            for i in range(0, d_model, 2):   # for each dimension of the each position\n","                pe[pos, i]     = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n","                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n","        \n","        pe = pe.unsqueeze(0)   # include the batch size, (1, max_len, d_model)\n","        \n","        return pe\n","        \n","        \n","    def forward(self, embedding, layer_idx):\n","        if layer_idx == 0:\n","            embedding = self.embed(embedding) * math.sqrt(self.d_model) # run in first time step only\n","                                                                        # (batch_size, max_words, d_model)\n","            \n","        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with\n","                                                      # the same batch size as encoded_words\n","\n","        # embedding: (batch_size, max_len, d_model)\n","        # te: (batch_size, d_model) --> (batch_size, 1, d_model) -> (batch_size, max_len, d_model)\n","        embedding += self.te[:, layer_idx, :].unsqueeze(1).repeat(1, embedding.size(1), 1)\n","        \n","        embedding = self.dropout(embedding)\n","        \n","        \n","        return embedding\n","        "]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":112,"status":"ok","timestamp":1655405821710,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"R6HkLslc22y5"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    \n","    def __init__(self, heads, d_model):\n","        \n","        super(MultiHeadAttention, self).__init__()\n","        \n","        assert d_model % heads == 0\n","        \n","        self.d_k = d_model // heads\n","        self.heads = heads\n","        self.dropout = nn.Dropout(0.1)\n","        self.query = nn.Linear(d_model, d_model)\n","        self.key = nn.Linear(d_model, d_model)\n","        self.value = nn.Linear(d_model, d_model)\n","        self.concat = nn.Linear(d_model, d_model)\n","        \n","        \n","    def forward(self, query, key, value, mask):\n","        \"\"\"\n","        query, key, value of shape: (batch_size, max_len, 512)\n","        mask of shape: (batch_size, 1, 1, max_words)\n","        \"\"\"\n","        # (batch_size, max_len, 512)\n","        query = self.query(query)\n","        key   = self.key(key)        \n","        value = self.value(value)   \n","        \n","        #                                                      8   64                   8            64\n","        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n","        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n","        key   = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n","        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n","        \n","        # (batch_size, h, max_len, d_k) dot (batch_size, h, max_len, d_k).transpose()\n","        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n","        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1)) # query.size(-1) = d_k\n","        scores = scores.masked_fill(mask == 0, -1e9)    # (batch_size, h, max_len, max_len)\n","                                                        # '-1e9' as a tiny value that softmax ignore them, not doing\n","                                                        # the attention operation on padded values\n","        weights = F.softmax(scores, dim=-1)           # (batch_size, h, max_len, max_len)\n","        weights = self.dropout(weights)\n","        \n","        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n","        context = torch.matmul(weights, value)\n","        \n","        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n","        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n","        # (batch_size, max_len, h * d_k)\n","        interacted = self.concat(context)\n","        \n","        \n","        return interacted\n","        "]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":119,"status":"ok","timestamp":1655405821719,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"EmrJcp7l22y7"},"outputs":[],"source":["class FeedForward(nn.Module):\n","\n","    def __init__(self, d_model, middle_dim=2048):\n","        super(FeedForward, self).__init__()\n","        \n","        self.fc1 = nn.Linear(d_model, middle_dim)\n","        self.fc2 = nn.Linear(middle_dim, d_model)\n","        self.dropout = nn.Dropout(0.1)\n","\n","\n","    def forward(self, x):\n","        out = F.relu(self.fc1(x))\n","        out = self.fc2(self.dropout(out))\n","        return out\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":122,"status":"ok","timestamp":1655405821723,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"p64usJgL22y9"},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, heads):\n","        super(EncoderLayer, self).__init__()\n","        self.layernorm = nn.LayerNorm(d_model)    # d_model = 512\n","        self.self_multihead = MultiHeadAttention(heads, d_model)\n","        self.feed_forward = FeedForward(d_model)\n","        self.dropout = nn.Dropout(0.1)\n","\n","\n","    def forward(self, embeddings, mask):\n","        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n","        interacted = self.layernorm(interacted + embeddings)\n","        feed_forward_out = self.dropout(self.feed_forward(interacted))\n","        encoded = self.layernorm(feed_forward_out + interacted)\n","        \n","        \n","        return encoded\n","\n","        "]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":120,"status":"ok","timestamp":1655405821724,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"x_6v93vF22y_"},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    \n","    def __init__(self, d_model, heads):\n","        super(DecoderLayer, self).__init__()\n","        self.layernorm = nn.LayerNorm(d_model)\n","        self.self_multihead = MultiHeadAttention(heads, d_model)\n","        self.src_multihead = MultiHeadAttention(heads, d_model)\n","        self.feed_forward = FeedForward(d_model)\n","        self.dropout = nn.Dropout(0.1)\n","        \n","\n","    def forward(self, embeddings, encoded, src_mask, target_mask):\n","        \n","        # interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n","        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n","        \n","        # interacted = self.layernorm(interacted + embeddings)\n","        query = self.layernorm(query + embeddings)\n","        \n","        # query -> self_attention from Decoder, key and value -> encoded from Encoder\n","        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n","        # query = query, key and value = encoded\n","        interacted = self.layernorm(interacted + query)\n","        \n","        feed_forward_out = self.dropout(self.feed_forward(interacted))\n","        decoded = self.layernorm(feed_forward_out + interacted)\n","        \n","        \n","        return decoded\n","\n","        "]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":121,"status":"ok","timestamp":1655405821726,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"3I-MNKc822zA"},"outputs":[],"source":["# class Transformer(nn.Module):\n","    \n","#     def __init__(self, d_model, heads, num_layers, word_map):\n","#         super(Transformer, self).__init__()\n","        \n","#         self.d_model = d_model\n","#         self.vocab_size = len(word_map)\n","#         self.embed = Embeddings(self.vocab_size, d_model)\n","#         self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)]) # 6 layers\n","#         self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n","#         self.logit = nn.Linear(d_model, self.vocab_size)\n","        \n","#     def encode(self, src_words, src_mask):\n","#         src_embeddings = self.embed(src_words)\n","#         for layer in self.encoder:\n","#             src_embeddings = layer(src_embeddings, src_mask)\n","#         return src_embeddings\n","    \n","#     def decode(self, target_words, target_mask, src_embeddings, src_mask):\n","#         tgt_embeddings = self.embed(target_words)\n","#         for layer in self.decoder:\n","#             tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n","#         return tgt_embeddings\n","        \n","#     def forward(self, src_words, src_mask, target_words, target_mask):\n","#         encoded = self.encode(src_words, src_mask)\n","#         decoded = self.decode(target_words, target_mask, encoded, src_mask)\n","#         out = F.log_softmax(self.logit(decoded), dim=2)    # (batch_size, max_words, vocab_size)\n","#         return out"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":120,"status":"ok","timestamp":1655405821727,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"M6rKihz-3Znx"},"outputs":[],"source":["class Transformer(nn.Module):\n","    \n","    def __init__(self, d_model, heads, num_layers, word_map):\n","        super(Transformer, self).__init__()\n","        \n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.vocab_size = len(word_map)\n","        self.embed = Embeddings(self.vocab_size, d_model, num_layers=num_layers)\n","        self.encoder = EncoderLayer(d_model, heads) \n","        self.decoder = DecoderLayer(d_model, heads)\n","        self.logit = nn.Linear(d_model, self.vocab_size)\n","        \n","        \n","    def encode(self, src_embeddings, src_mask):\n","        for i in range(self.num_layers):\n","            src_embeddings = self.embed(src_embeddings, i)\n","            src_embeddings = self.encoder(src_embeddings, src_mask)\n","        return src_embeddings\n","    \n","    \n","    def decode(self, tgt_embeddings, target_mask, src_embeddings, src_mask):\n","        for i in range(self.num_layers):\n","            tgt_embeddings = self.embed(tgt_embeddings, i)\n","            tgt_embeddings = self.decoder(tgt_embeddings, src_embeddings, src_mask, target_mask)\n","        return tgt_embeddings\n","    \n","\n","    \n","    def forward(self, src_words, src_mask, target_words, target_mask):\n","        encoded = self.encode(src_words, src_mask)\n","        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n","        out = F.log_softmax(self.logit(decoded), dim=2) # (batch_size, max_words, vocab_size)\n","        \n","        return out\n","    \n","    "]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":120,"status":"ok","timestamp":1655405821729,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"yiUlFyoe22zK"},"outputs":[],"source":["class AdamWarmup:\n","    \n","    def __init__(self, model_size, warmup_steps, optimizer):\n","        \n","        self.model_size = model_size\n","        self.warmup_steps = warmup_steps\n","        self.optimizer = optimizer\n","        self.current_step = 0\n","        self.lr = 0\n","        \n","        \n","    def get_lr(self):\n","        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n","        \n","\n","    def step(self):\n","        \n","        # Increment the number of steps each time we call the step function\n","        self.current_step += 1\n","        lr = self.get_lr()\n","        for param_group in self.optimizer.param_groups:\n","            param_group['lr'] = lr\n","        \n","        # update the learning rate\n","        self.lr = lr\n","        self.optimizer.step()\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":120,"status":"ok","timestamp":1655405821730,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"CNBmK6KR22zL"},"outputs":[],"source":["class LossWithLS(nn.Module):\n","\n","    def __init__(self, size, smooth):\n","        super(LossWithLS, self).__init__()\n","\n","        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n","        # self.criterion = nn.KLDivLoss(reduction=)\n","\n","        self.confidence = 1.0 - smooth\n","        self.smooth = smooth\n","        self.size = size    # size of predection, which is vocab_size\n","        \n","\n","    def forward(self, prediction, target, mask):\n","        \"\"\"\n","        prediction of shape: (batch_size, max_words, vocab_size)\n","        target and mask of shape: (batch_size, max_words)\n","        \"\"\"\n","        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n","        target = target.contiguous().view(-1)   # (batch_size * max_words)\n","        mask = mask.float()\n","        mask = mask.view(-1)       # (batch_size * max_words)\n","        labels = prediction.data.clone()\n","        labels.fill_(self.smooth / (self.size - 1))\n","        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        \n","        loss = self.criterion(prediction, labels)    # (batch_size * max_words, vocab_size)\n","        \n","        loss = (loss.sum(1) * mask).sum() / mask.sum()  # loss.sum(1) --> (batch_size * max_words) 1d tensor\n","                                                        # '/ mask.sum()' sum over all the elements in the mask\n","        \n","        return loss\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13621,"status":"ok","timestamp":1655405835237,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"BrYATdGk22zN","outputId":"2767375b-cab1-4ace-92dc-c3c06706561e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]}],"source":["d_model = 512\n","heads = 8\n","\n","# num_layers = 3\n","num_layers = 6\n","\n","epochs = 10\n","\n","\n","\n","with open('WORDMAP_corpus.json', 'r') as j:\n","    word_map = json.load(j)\n","\n","\n","\n","transformer = Transformer(d_model=d_model, heads=heads, num_layers=num_layers, word_map=word_map).to(device)\n","\n","adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n","transformer_optimizer = AdamWarmup(model_size=d_model, warmup_steps=4000, optimizer=adam_optimizer)\n","\n","criterion = LossWithLS(len(word_map), 0.1)\n","\n"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":61,"status":"ok","timestamp":1655405835239,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"Z0whWohN22zN"},"outputs":[],"source":["def train(train_loader, transformer, criterion, epoch):\n","    \n","    transformer.train()\n","    sum_loss = 0\n","    count = 0\n","\n","    for i, (question, reply) in enumerate(train_loader):\n","        \n","        samples = question.shape[0]    # batch_size\n","\n","        # Move to device\n","        question = question.to(device)\n","        reply = reply.to(device)\n","\n","        # question    : <start>  I     went   home <end>\n","        # reply_input : <start>  I     went   home\n","        # reply_target:   I     went   home   <end>\n","        \n","        # Prepare Target Data\n","        reply_input = reply[:, :-1] # start .. before <end> token\n","        reply_target = reply[:, 1:] # after <start> token .. up to <end> token\n","\n","        # Create mask and add dimensions\n","        question_mask, reply_input_mask, reply_target_mask = create_masks(question, reply_input, reply_target)\n","\n","        # Get the transformer outputs\n","        out = transformer(question, question_mask, reply_input, reply_input_mask)\n","\n","        # Compute the loss\n","        loss = criterion(out, reply_target, reply_target_mask)\n","        \n","        # Backprop\n","        transformer_optimizer.optimizer.zero_grad()\n","        loss.backward()\n","        transformer_optimizer.step()\n","        \n","        sum_loss += loss.item() * samples\n","        count += samples    # at the last batch for an epoch, the count = len(train_loader * 100\n","        \n","        if i % 100 == 0:\n","            print(f\"Epoch [{epoch}][{i}/{len(train_loader)}]\\tLoss: {sum_loss/count:.3f}\")\n","\n","            "]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":54,"status":"ok","timestamp":1655405835240,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"Gulg5aaX22zO"},"outputs":[],"source":["def evaluate(transformer, question, question_mask, max_len, word_map):\n","    \"\"\"\n","    Performs Greedy (search) Decoding with a batch size of 1\n","    \"\"\"\n","\n","    rev_word_map = {v: k for k, v in word_map.items()}\n","    transformer.eval()\n","    start_token = word_map['<start>']\n","    encoded = transformer.encode(question, question_mask)\n","    words = torch.LongTensor([[start_token]]).to(device) # (1, 1)\n","    \n","\n","    for step in range(max_len - 1):\n","        size = words.shape[1]\n","        target_mask = torch.tril(torch.ones(size, size)).type(dtype=torch.uint8)\n","        target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n","        decoded = transformer.decode(words, target_mask, encoded, question_mask)\n","        # decoded is of (batch_size, max_words, vocab_size) --> (1, 1, vocab_size)\n","        \n","        predictions = transformer.logit(decoded[:, -1]) # decoded[:, -1] --> predictions of last word to generate\n","        # predictions is of (max_words, vocab_size) --> (1, vocab_size)\n","        \n","        _, next_word = torch.max(predictions, dim=1) # (1, 1), dim = 1 --> dim of vocab\n","        next_word = next_word.item()\n","        if next_word == word_map['<end>']:\n","            break\n","        words = torch.cat([words, torch.LongTensor([[next_word]]).to(device)], dim=1)   # (1, step+2)\n","        \n","    # Construct Sentence\n","    if words.dim() == 2:\n","        words = words.squeeze(0) # 1d tensor\n","        words = words.tolist()\n","        \n","    sen_idx = [w for w in words if w not in {word_map['<start>']}] # current   : <start>\n","                                                                   # generated : I went home <end>\n","    \n","    sentence = ' '.join([rev_word_map[sen_idx[k]] for k in range(len(sen_idx))])\n","    \n","    \n","    \n","    return sentence\n","    "]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4851899,"status":"ok","timestamp":1655412721563,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"HKhNTlPK22zQ","outputId":"1f7861e0-20e1-4f48-e93b-ce83f093ace5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0][0/3463]\tLoss: 8.660\n","Epoch [0][100/3463]\tLoss: 7.907\n","Epoch [0][200/3463]\tLoss: 7.255\n","Epoch [0][300/3463]\tLoss: 6.736\n","Epoch [0][400/3463]\tLoss: 6.405\n","Epoch [0][500/3463]\tLoss: 6.199\n","Epoch [0][600/3463]\tLoss: 6.058\n","Epoch [0][700/3463]\tLoss: 5.955\n","Epoch [0][800/3463]\tLoss: 5.876\n","Epoch [0][900/3463]\tLoss: 5.814\n","Epoch [0][1000/3463]\tLoss: 5.764\n","Epoch [0][1100/3463]\tLoss: 5.717\n","Epoch [0][1200/3463]\tLoss: 5.668\n","Epoch [0][1300/3463]\tLoss: 5.622\n","Epoch [0][1400/3463]\tLoss: 5.580\n","Epoch [0][1500/3463]\tLoss: 5.540\n","Epoch [0][1600/3463]\tLoss: 5.502\n","Epoch [0][1700/3463]\tLoss: 5.465\n","Epoch [0][1800/3463]\tLoss: 5.431\n","Epoch [0][1900/3463]\tLoss: 5.398\n","Epoch [0][2000/3463]\tLoss: 5.368\n","Epoch [0][2100/3463]\tLoss: 5.339\n","Epoch [0][2200/3463]\tLoss: 5.313\n","Epoch [0][2300/3463]\tLoss: 5.289\n","Epoch [0][2400/3463]\tLoss: 5.265\n","Epoch [0][2500/3463]\tLoss: 5.244\n","Epoch [0][2600/3463]\tLoss: 5.222\n","Epoch [0][2700/3463]\tLoss: 5.202\n","Epoch [0][2800/3463]\tLoss: 5.184\n","Epoch [0][2900/3463]\tLoss: 5.166\n","Epoch [0][3000/3463]\tLoss: 5.149\n","Epoch [0][3100/3463]\tLoss: 5.132\n","Epoch [0][3200/3463]\tLoss: 5.116\n","Epoch [0][3300/3463]\tLoss: 5.101\n","Epoch [0][3400/3463]\tLoss: 5.087\n","Epoch [1][0/3463]\tLoss: 4.452\n","Epoch [1][100/3463]\tLoss: 4.575\n","Epoch [1][200/3463]\tLoss: 4.584\n","Epoch [1][300/3463]\tLoss: 4.584\n","Epoch [1][400/3463]\tLoss: 4.584\n","Epoch [1][500/3463]\tLoss: 4.584\n","Epoch [1][600/3463]\tLoss: 4.587\n","Epoch [1][700/3463]\tLoss: 4.588\n","Epoch [1][800/3463]\tLoss: 4.586\n","Epoch [1][900/3463]\tLoss: 4.582\n","Epoch [1][1000/3463]\tLoss: 4.579\n","Epoch [1][1100/3463]\tLoss: 4.577\n","Epoch [1][1200/3463]\tLoss: 4.575\n","Epoch [1][1300/3463]\tLoss: 4.573\n","Epoch [1][1400/3463]\tLoss: 4.572\n","Epoch [1][1500/3463]\tLoss: 4.571\n","Epoch [1][1600/3463]\tLoss: 4.568\n","Epoch [1][1700/3463]\tLoss: 4.565\n","Epoch [1][1800/3463]\tLoss: 4.563\n","Epoch [1][1900/3463]\tLoss: 4.559\n","Epoch [1][2000/3463]\tLoss: 4.558\n","Epoch [1][2100/3463]\tLoss: 4.555\n","Epoch [1][2200/3463]\tLoss: 4.552\n","Epoch [1][2300/3463]\tLoss: 4.549\n","Epoch [1][2400/3463]\tLoss: 4.546\n","Epoch [1][2500/3463]\tLoss: 4.544\n","Epoch [1][2600/3463]\tLoss: 4.541\n","Epoch [1][2700/3463]\tLoss: 4.539\n","Epoch [1][2800/3463]\tLoss: 4.537\n","Epoch [1][2900/3463]\tLoss: 4.535\n","Epoch [1][3000/3463]\tLoss: 4.533\n","Epoch [1][3100/3463]\tLoss: 4.530\n","Epoch [1][3200/3463]\tLoss: 4.527\n","Epoch [1][3300/3463]\tLoss: 4.524\n","Epoch [1][3400/3463]\tLoss: 4.522\n","Epoch [2][0/3463]\tLoss: 4.409\n","Epoch [2][100/3463]\tLoss: 4.417\n","Epoch [2][200/3463]\tLoss: 4.406\n","Epoch [2][300/3463]\tLoss: 4.410\n","Epoch [2][400/3463]\tLoss: 4.411\n","Epoch [2][500/3463]\tLoss: 4.412\n","Epoch [2][600/3463]\tLoss: 4.412\n","Epoch [2][700/3463]\tLoss: 4.413\n","Epoch [2][800/3463]\tLoss: 4.413\n","Epoch [2][900/3463]\tLoss: 4.412\n","Epoch [2][1000/3463]\tLoss: 4.413\n","Epoch [2][1100/3463]\tLoss: 4.411\n","Epoch [2][1200/3463]\tLoss: 4.411\n","Epoch [2][1300/3463]\tLoss: 4.410\n","Epoch [2][1400/3463]\tLoss: 4.408\n","Epoch [2][1500/3463]\tLoss: 4.408\n","Epoch [2][1600/3463]\tLoss: 4.408\n","Epoch [2][1700/3463]\tLoss: 4.406\n","Epoch [2][1800/3463]\tLoss: 4.406\n","Epoch [2][1900/3463]\tLoss: 4.405\n","Epoch [2][2000/3463]\tLoss: 4.405\n","Epoch [2][2100/3463]\tLoss: 4.404\n","Epoch [2][2200/3463]\tLoss: 4.404\n","Epoch [2][2300/3463]\tLoss: 4.403\n","Epoch [2][2400/3463]\tLoss: 4.403\n","Epoch [2][2500/3463]\tLoss: 4.402\n","Epoch [2][2600/3463]\tLoss: 4.401\n","Epoch [2][2700/3463]\tLoss: 4.401\n","Epoch [2][2800/3463]\tLoss: 4.401\n","Epoch [2][2900/3463]\tLoss: 4.401\n","Epoch [2][3000/3463]\tLoss: 4.400\n","Epoch [2][3100/3463]\tLoss: 4.399\n","Epoch [2][3200/3463]\tLoss: 4.398\n","Epoch [2][3300/3463]\tLoss: 4.397\n","Epoch [2][3400/3463]\tLoss: 4.397\n","Epoch [3][0/3463]\tLoss: 4.350\n","Epoch [3][100/3463]\tLoss: 4.322\n","Epoch [3][200/3463]\tLoss: 4.322\n","Epoch [3][300/3463]\tLoss: 4.328\n","Epoch [3][400/3463]\tLoss: 4.334\n","Epoch [3][500/3463]\tLoss: 4.334\n","Epoch [3][600/3463]\tLoss: 4.335\n","Epoch [3][700/3463]\tLoss: 4.333\n","Epoch [3][800/3463]\tLoss: 4.332\n","Epoch [3][900/3463]\tLoss: 4.336\n","Epoch [3][1000/3463]\tLoss: 4.336\n","Epoch [3][1100/3463]\tLoss: 4.337\n","Epoch [3][1200/3463]\tLoss: 4.336\n","Epoch [3][1300/3463]\tLoss: 4.336\n","Epoch [3][1400/3463]\tLoss: 4.336\n","Epoch [3][1500/3463]\tLoss: 4.335\n","Epoch [3][1600/3463]\tLoss: 4.334\n","Epoch [3][1700/3463]\tLoss: 4.334\n","Epoch [3][1800/3463]\tLoss: 4.335\n","Epoch [3][1900/3463]\tLoss: 4.335\n","Epoch [3][2000/3463]\tLoss: 4.335\n","Epoch [3][2100/3463]\tLoss: 4.335\n","Epoch [3][2200/3463]\tLoss: 4.335\n","Epoch [3][2300/3463]\tLoss: 4.334\n","Epoch [3][2400/3463]\tLoss: 4.334\n","Epoch [3][2500/3463]\tLoss: 4.335\n","Epoch [3][2600/3463]\tLoss: 4.335\n","Epoch [3][2700/3463]\tLoss: 4.335\n","Epoch [3][2800/3463]\tLoss: 4.334\n","Epoch [3][2900/3463]\tLoss: 4.334\n","Epoch [3][3000/3463]\tLoss: 4.334\n","Epoch [3][3100/3463]\tLoss: 4.334\n","Epoch [3][3200/3463]\tLoss: 4.334\n","Epoch [3][3300/3463]\tLoss: 4.334\n","Epoch [3][3400/3463]\tLoss: 4.334\n","Epoch [4][0/3463]\tLoss: 4.106\n","Epoch [4][100/3463]\tLoss: 4.283\n","Epoch [4][200/3463]\tLoss: 4.270\n","Epoch [4][300/3463]\tLoss: 4.273\n","Epoch [4][400/3463]\tLoss: 4.276\n","Epoch [4][500/3463]\tLoss: 4.276\n","Epoch [4][600/3463]\tLoss: 4.279\n","Epoch [4][700/3463]\tLoss: 4.282\n","Epoch [4][800/3463]\tLoss: 4.284\n","Epoch [4][900/3463]\tLoss: 4.285\n","Epoch [4][1000/3463]\tLoss: 4.285\n","Epoch [4][1100/3463]\tLoss: 4.285\n","Epoch [4][1200/3463]\tLoss: 4.286\n","Epoch [4][1300/3463]\tLoss: 4.286\n","Epoch [4][1400/3463]\tLoss: 4.288\n","Epoch [4][1500/3463]\tLoss: 4.289\n","Epoch [4][1600/3463]\tLoss: 4.291\n","Epoch [4][1700/3463]\tLoss: 4.290\n","Epoch [4][1800/3463]\tLoss: 4.291\n","Epoch [4][1900/3463]\tLoss: 4.290\n","Epoch [4][2000/3463]\tLoss: 4.290\n","Epoch [4][2100/3463]\tLoss: 4.290\n","Epoch [4][2200/3463]\tLoss: 4.290\n","Epoch [4][2300/3463]\tLoss: 4.290\n","Epoch [4][2400/3463]\tLoss: 4.291\n","Epoch [4][2500/3463]\tLoss: 4.291\n","Epoch [4][2600/3463]\tLoss: 4.291\n","Epoch [4][2700/3463]\tLoss: 4.290\n","Epoch [4][2800/3463]\tLoss: 4.290\n","Epoch [4][2900/3463]\tLoss: 4.291\n","Epoch [4][3000/3463]\tLoss: 4.291\n","Epoch [4][3100/3463]\tLoss: 4.291\n","Epoch [4][3200/3463]\tLoss: 4.291\n","Epoch [4][3300/3463]\tLoss: 4.291\n","Epoch [4][3400/3463]\tLoss: 4.291\n","Epoch [5][0/3463]\tLoss: 4.077\n","Epoch [5][100/3463]\tLoss: 4.263\n","Epoch [5][200/3463]\tLoss: 4.255\n","Epoch [5][300/3463]\tLoss: 4.253\n","Epoch [5][400/3463]\tLoss: 4.250\n","Epoch [5][500/3463]\tLoss: 4.253\n","Epoch [5][600/3463]\tLoss: 4.252\n","Epoch [5][700/3463]\tLoss: 4.253\n","Epoch [5][800/3463]\tLoss: 4.252\n","Epoch [5][900/3463]\tLoss: 4.252\n","Epoch [5][1000/3463]\tLoss: 4.252\n","Epoch [5][1100/3463]\tLoss: 4.253\n","Epoch [5][1200/3463]\tLoss: 4.251\n","Epoch [5][1300/3463]\tLoss: 4.251\n","Epoch [5][1400/3463]\tLoss: 4.253\n","Epoch [5][1500/3463]\tLoss: 4.254\n","Epoch [5][1600/3463]\tLoss: 4.255\n","Epoch [5][1700/3463]\tLoss: 4.257\n","Epoch [5][1800/3463]\tLoss: 4.258\n","Epoch [5][1900/3463]\tLoss: 4.258\n","Epoch [5][2000/3463]\tLoss: 4.258\n","Epoch [5][2100/3463]\tLoss: 4.259\n","Epoch [5][2200/3463]\tLoss: 4.259\n","Epoch [5][2300/3463]\tLoss: 4.259\n","Epoch [5][2400/3463]\tLoss: 4.259\n","Epoch [5][2500/3463]\tLoss: 4.259\n","Epoch [5][2600/3463]\tLoss: 4.259\n","Epoch [5][2700/3463]\tLoss: 4.258\n","Epoch [5][2800/3463]\tLoss: 4.260\n","Epoch [5][2900/3463]\tLoss: 4.260\n","Epoch [5][3000/3463]\tLoss: 4.260\n","Epoch [5][3100/3463]\tLoss: 4.260\n","Epoch [5][3200/3463]\tLoss: 4.260\n","Epoch [5][3300/3463]\tLoss: 4.259\n","Epoch [5][3400/3463]\tLoss: 4.259\n","Epoch [6][0/3463]\tLoss: 4.122\n","Epoch [6][100/3463]\tLoss: 4.235\n","Epoch [6][200/3463]\tLoss: 4.222\n","Epoch [6][300/3463]\tLoss: 4.221\n","Epoch [6][400/3463]\tLoss: 4.219\n","Epoch [6][500/3463]\tLoss: 4.216\n","Epoch [6][600/3463]\tLoss: 4.215\n","Epoch [6][700/3463]\tLoss: 4.212\n","Epoch [6][800/3463]\tLoss: 4.216\n","Epoch [6][900/3463]\tLoss: 4.218\n","Epoch [6][1000/3463]\tLoss: 4.218\n","Epoch [6][1100/3463]\tLoss: 4.219\n","Epoch [6][1200/3463]\tLoss: 4.222\n","Epoch [6][1300/3463]\tLoss: 4.223\n","Epoch [6][1400/3463]\tLoss: 4.224\n","Epoch [6][1500/3463]\tLoss: 4.225\n","Epoch [6][1600/3463]\tLoss: 4.226\n","Epoch [6][1700/3463]\tLoss: 4.228\n","Epoch [6][1800/3463]\tLoss: 4.230\n","Epoch [6][1900/3463]\tLoss: 4.230\n","Epoch [6][2000/3463]\tLoss: 4.231\n","Epoch [6][2100/3463]\tLoss: 4.232\n","Epoch [6][2200/3463]\tLoss: 4.232\n","Epoch [6][2300/3463]\tLoss: 4.233\n","Epoch [6][2400/3463]\tLoss: 4.234\n","Epoch [6][2500/3463]\tLoss: 4.235\n","Epoch [6][2600/3463]\tLoss: 4.236\n","Epoch [6][2700/3463]\tLoss: 4.236\n","Epoch [6][2800/3463]\tLoss: 4.235\n","Epoch [6][2900/3463]\tLoss: 4.235\n","Epoch [6][3000/3463]\tLoss: 4.236\n","Epoch [6][3100/3463]\tLoss: 4.236\n","Epoch [6][3200/3463]\tLoss: 4.236\n","Epoch [6][3300/3463]\tLoss: 4.236\n","Epoch [6][3400/3463]\tLoss: 4.235\n","Epoch [7][0/3463]\tLoss: 4.104\n","Epoch [7][100/3463]\tLoss: 4.191\n","Epoch [7][200/3463]\tLoss: 4.185\n","Epoch [7][300/3463]\tLoss: 4.194\n","Epoch [7][400/3463]\tLoss: 4.200\n","Epoch [7][500/3463]\tLoss: 4.205\n","Epoch [7][600/3463]\tLoss: 4.205\n","Epoch [7][700/3463]\tLoss: 4.202\n","Epoch [7][800/3463]\tLoss: 4.204\n","Epoch [7][900/3463]\tLoss: 4.203\n","Epoch [7][1000/3463]\tLoss: 4.202\n","Epoch [7][1100/3463]\tLoss: 4.201\n","Epoch [7][1200/3463]\tLoss: 4.204\n","Epoch [7][1300/3463]\tLoss: 4.205\n","Epoch [7][1400/3463]\tLoss: 4.207\n","Epoch [7][1500/3463]\tLoss: 4.207\n","Epoch [7][1600/3463]\tLoss: 4.209\n","Epoch [7][1700/3463]\tLoss: 4.209\n","Epoch [7][1800/3463]\tLoss: 4.210\n","Epoch [7][1900/3463]\tLoss: 4.210\n","Epoch [7][2000/3463]\tLoss: 4.210\n","Epoch [7][2100/3463]\tLoss: 4.211\n","Epoch [7][2200/3463]\tLoss: 4.211\n","Epoch [7][2300/3463]\tLoss: 4.212\n","Epoch [7][2400/3463]\tLoss: 4.212\n","Epoch [7][2500/3463]\tLoss: 4.213\n","Epoch [7][2600/3463]\tLoss: 4.213\n","Epoch [7][2700/3463]\tLoss: 4.213\n","Epoch [7][2800/3463]\tLoss: 4.213\n","Epoch [7][2900/3463]\tLoss: 4.213\n","Epoch [7][3000/3463]\tLoss: 4.213\n","Epoch [7][3100/3463]\tLoss: 4.214\n","Epoch [7][3200/3463]\tLoss: 4.214\n","Epoch [7][3300/3463]\tLoss: 4.214\n","Epoch [7][3400/3463]\tLoss: 4.215\n","Epoch [8][0/3463]\tLoss: 4.247\n","Epoch [8][100/3463]\tLoss: 4.165\n","Epoch [8][200/3463]\tLoss: 4.168\n","Epoch [8][300/3463]\tLoss: 4.172\n","Epoch [8][400/3463]\tLoss: 4.172\n","Epoch [8][500/3463]\tLoss: 4.181\n","Epoch [8][600/3463]\tLoss: 4.179\n","Epoch [8][700/3463]\tLoss: 4.180\n","Epoch [8][800/3463]\tLoss: 4.180\n","Epoch [8][900/3463]\tLoss: 4.183\n","Epoch [8][1000/3463]\tLoss: 4.187\n","Epoch [8][1100/3463]\tLoss: 4.186\n","Epoch [8][1200/3463]\tLoss: 4.187\n","Epoch [8][1300/3463]\tLoss: 4.188\n","Epoch [8][1400/3463]\tLoss: 4.190\n","Epoch [8][1500/3463]\tLoss: 4.191\n","Epoch [8][1600/3463]\tLoss: 4.192\n","Epoch [8][1700/3463]\tLoss: 4.193\n","Epoch [8][1800/3463]\tLoss: 4.192\n","Epoch [8][1900/3463]\tLoss: 4.194\n","Epoch [8][2000/3463]\tLoss: 4.194\n","Epoch [8][2100/3463]\tLoss: 4.194\n","Epoch [8][2200/3463]\tLoss: 4.195\n","Epoch [8][2300/3463]\tLoss: 4.195\n","Epoch [8][2400/3463]\tLoss: 4.195\n","Epoch [8][2500/3463]\tLoss: 4.195\n","Epoch [8][2600/3463]\tLoss: 4.196\n","Epoch [8][2700/3463]\tLoss: 4.196\n","Epoch [8][2800/3463]\tLoss: 4.195\n","Epoch [8][2900/3463]\tLoss: 4.195\n","Epoch [8][3000/3463]\tLoss: 4.196\n","Epoch [8][3100/3463]\tLoss: 4.197\n","Epoch [8][3200/3463]\tLoss: 4.198\n","Epoch [8][3300/3463]\tLoss: 4.198\n","Epoch [8][3400/3463]\tLoss: 4.198\n","Epoch [9][0/3463]\tLoss: 4.212\n","Epoch [9][100/3463]\tLoss: 4.175\n","Epoch [9][200/3463]\tLoss: 4.156\n","Epoch [9][300/3463]\tLoss: 4.156\n","Epoch [9][400/3463]\tLoss: 4.159\n","Epoch [9][500/3463]\tLoss: 4.162\n","Epoch [9][600/3463]\tLoss: 4.163\n","Epoch [9][700/3463]\tLoss: 4.166\n","Epoch [9][800/3463]\tLoss: 4.169\n","Epoch [9][900/3463]\tLoss: 4.170\n","Epoch [9][1000/3463]\tLoss: 4.171\n","Epoch [9][1100/3463]\tLoss: 4.171\n","Epoch [9][1200/3463]\tLoss: 4.170\n","Epoch [9][1300/3463]\tLoss: 4.173\n","Epoch [9][1400/3463]\tLoss: 4.174\n","Epoch [9][1500/3463]\tLoss: 4.175\n","Epoch [9][1600/3463]\tLoss: 4.176\n","Epoch [9][1700/3463]\tLoss: 4.177\n","Epoch [9][1800/3463]\tLoss: 4.177\n","Epoch [9][1900/3463]\tLoss: 4.177\n","Epoch [9][2000/3463]\tLoss: 4.179\n","Epoch [9][2100/3463]\tLoss: 4.180\n","Epoch [9][2200/3463]\tLoss: 4.181\n","Epoch [9][2300/3463]\tLoss: 4.180\n","Epoch [9][2400/3463]\tLoss: 4.181\n","Epoch [9][2500/3463]\tLoss: 4.181\n","Epoch [9][2600/3463]\tLoss: 4.182\n","Epoch [9][2700/3463]\tLoss: 4.181\n","Epoch [9][2800/3463]\tLoss: 4.182\n","Epoch [9][2900/3463]\tLoss: 4.182\n","Epoch [9][3000/3463]\tLoss: 4.183\n","Epoch [9][3100/3463]\tLoss: 4.183\n","Epoch [9][3200/3463]\tLoss: 4.183\n","Epoch [9][3300/3463]\tLoss: 4.183\n","Epoch [9][3400/3463]\tLoss: 4.183\n"]}],"source":["for epoch in range(epochs):\n","    \n","    train(train_loader, transformer, criterion, epoch)\n","    \n","    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n","    \n","    # torch.save(state, f'checkpoint_' + str(epoch) + '.pth.tar')\n","    torch.save(state, f'checkpoint_{str(epoch)}.pth.tar')\n","\n","\n"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":315,"status":"ok","timestamp":1655412937181,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"J4rPJi3s22zR"},"outputs":[],"source":["checkpoint = torch.load(f'checkpoint_{epoch}.pth.tar')\n","\n","transformer = checkpoint['transformer']\n"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21974,"status":"ok","timestamp":1655412961114,"user":{"displayName":"Mohamed Nassar","userId":"03808462448498335793"},"user_tz":-120},"id":"gIA0pYhY22zR","outputId":"210c1830-53b5-4724-f2e3-120104f1925d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: how are you\n","Maximum Reply Length: 5\n","i dont know\n","Question: quit\n"]}],"source":["while True:\n","    \n","    question = input(\"Question: \") \n","    \n","    if question == 'quit':\n","        break\n","    \n","    max_len = input(\"Maximum Reply Length: \")\n","    enc_qus = [ word_map.get(word, word_map['<unk>'])  for word in question.split() ]\n","    \n","    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0) # 2d dim\n","    question_mask = (question != 0).to(device).unsqueeze(1).unsqueeze(1) # 4d dim, as in creat_mask_function\n","    \n","    sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n","    print(sentence)\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"transformer chatbot.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
